{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Face Mask Detection.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "mount_file_id": "1WqGTGN0YlObq2Jt8Rf2EDBeS9YyK5jDt",
      "authorship_tag": "ABX9TyMD2MiFU3dfSMMkXUEIcj8i",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Suchitra-V31/Deep_Learning_Projects/blob/main/Face_Mask_Detection.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "In this dataset we are going to detect whether the person is wearing mask or not.This dataset consists of 1350 images."
      ],
      "metadata": {
        "id": "07blpyLM0qGP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Import the necessary libraries**"
      ],
      "metadata": {
        "id": "R6Dof-GV1Mv6"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "XI0zQSOtm364"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import cv2\n",
        "import os \n",
        "import tensorflow\n",
        "from tensorflow import keras\n"
      ],
      "metadata": {
        "id": "MgiDcqFGsWxY"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.preprocessing import LabelEncoder\n",
        "from tensorflow.keras.utils import to_categorical"
      ],
      "metadata": {
        "id": "jsMTkzik4KNK"
      },
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.models import Sequential\n",
        "from keras.layers import Conv2D,MaxPooling2D,BatchNormalization,Dense,Flatten,Dropout\n"
      ],
      "metadata": {
        "id": "spZn6mBUueds"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Get the Data**"
      ],
      "metadata": {
        "id": "kwtxHBwx1TQz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "data_path='/content/drive/MyDrive/Datasets/Face mask dataset/dataset'"
      ],
      "metadata": {
        "id": "TNS6sIv2u6Yx"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data=[]\n",
        "label=[]\n",
        "for folder in os.listdir(data_path):\n",
        "  for file in os.listdir(os.path.join(data_path,folder)):\n",
        "    if file.endswith(\"jpg\"):\n",
        "      label.append(folder)\n",
        "      img=cv2.imread(os.path.join(data_path,folder,file))\n",
        "      img_rgb=cv2.cvtColor(img,cv2.COLOR_BGR2RGB)\n",
        "      img_resize=cv2.resize(img_rgb,(128,128))\n",
        "      data.append(img_resize)\n",
        "    else:\n",
        "      continue"
      ],
      "metadata": {
        "id": "HdeoQGsDvBqd"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Convert images into array**"
      ],
      "metadata": {
        "id": "ljyVgbqL1Xol"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "num_data=np.array(data)\n",
        "num_label=np.array(label)"
      ],
      "metadata": {
        "id": "jThzBdcBvBml"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "encoder=LabelEncoder()"
      ],
      "metadata": {
        "id": "C9_YtFHl20pf"
      },
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y=encoder.fit_transform(num_label)"
      ],
      "metadata": {
        "id": "ejXOHVaQ4TGt"
      },
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X=num_data/255\n",
        "y=to_categorical(y,2)"
      ],
      "metadata": {
        "id": "31o2aIW7vBgF"
      },
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Split the data into train/test**"
      ],
      "metadata": {
        "id": "SNa2nhsK1c8i"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split"
      ],
      "metadata": {
        "id": "Jak35f3xvBdF"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train,X_test,y_train,y_test=train_test_split(X,y,test_size=0.3,random_state=21)\n"
      ],
      "metadata": {
        "id": "hlTbxmggvBXy"
      },
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Create Model**"
      ],
      "metadata": {
        "id": "iuADUCO-1h4a"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model=Sequential()\n",
        "model.add(Conv2D(filters=64,kernel_size=(3,3),padding='Same',activation='relu',input_shape=(128,128,3)))\n",
        "model.add(MaxPooling2D(pool_size=(2,2)))\n",
        "\n",
        "model.add(Conv2D(filters=128,kernel_size=(3,3),padding='Same',activation='relu',input_shape=(128,128,3)))\n",
        "model.add(Conv2D(filters=128,kernel_size=(3,3),padding='Same',activation='relu',input_shape=(128,128,3)))\n",
        "model.add(Conv2D(filters=128,kernel_size=(3,3),padding='Same',activation='relu',input_shape=(128,128,3)))\n",
        "model.add(MaxPooling2D(pool_size=(2,2)))\n",
        "\n",
        "model.add(Flatten())\n",
        "model.add(Dense(128,activation='relu'))\n",
        "model.add(Dense(64,activation='relu'))\n",
        "model.add(Dropout(0.5))\n",
        "\n",
        "model.add(Dense(2,activation='softmax'))"
      ],
      "metadata": {
        "id": "kK9QHQ3wvBUV"
      },
      "execution_count": 41,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aMGZiiCFz0lO",
        "outputId": "85a6c0c3-33f7-4b89-ddf8-886c90cd0a71"
      },
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_4\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv2d_16 (Conv2D)          (None, 128, 128, 64)      1792      \n",
            "                                                                 \n",
            " max_pooling2d_8 (MaxPooling  (None, 64, 64, 64)       0         \n",
            " 2D)                                                             \n",
            "                                                                 \n",
            " conv2d_17 (Conv2D)          (None, 64, 64, 128)       73856     \n",
            "                                                                 \n",
            " conv2d_18 (Conv2D)          (None, 64, 64, 128)       147584    \n",
            "                                                                 \n",
            " conv2d_19 (Conv2D)          (None, 64, 64, 128)       147584    \n",
            "                                                                 \n",
            " max_pooling2d_9 (MaxPooling  (None, 32, 32, 128)      0         \n",
            " 2D)                                                             \n",
            "                                                                 \n",
            " flatten_4 (Flatten)         (None, 131072)            0         \n",
            "                                                                 \n",
            " dense_12 (Dense)            (None, 128)               16777344  \n",
            "                                                                 \n",
            " dense_13 (Dense)            (None, 64)                8256      \n",
            "                                                                 \n",
            " dropout_4 (Dropout)         (None, 64)                0         \n",
            "                                                                 \n",
            " dense_14 (Dense)            (None, 2)                 130       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 17,156,546\n",
            "Trainable params: 17,156,546\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Compile model**"
      ],
      "metadata": {
        "id": "qyxEEbi91lRq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model.compile(optimizer='adam',loss='binary_crossentropy',metrics=['accuracy'])"
      ],
      "metadata": {
        "id": "12TJRz63vBRV"
      },
      "execution_count": 43,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Train and test!!**"
      ],
      "metadata": {
        "id": "wWwBi0dM1n0S"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "final_model=model.fit(X_train,y_train,epochs=32,validation_data=(X_test,y_test))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5olAVG-NvBO1",
        "outputId": "4a76a451-dcae-4448-e9af-5dc7b82ea952"
      },
      "execution_count": 44,
      "outputs": [
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/32\n",
            "31/31 [==============================] - 210s 7s/step - loss: 0.7600 - accuracy: 0.5306 - val_loss: 0.6281 - val_accuracy: 0.6610\n",
            "Epoch 2/32\n",
            "31/31 [==============================] - 209s 7s/step - loss: 0.4158 - accuracy: 0.8515 - val_loss: 0.1670 - val_accuracy: 0.9274\n",
            "Epoch 3/32\n",
            "31/31 [==============================] - 209s 7s/step - loss: 0.1584 - accuracy: 0.9553 - val_loss: 0.0857 - val_accuracy: 0.9661\n",
            "Epoch 4/32\n",
            "31/31 [==============================] - 209s 7s/step - loss: 0.0805 - accuracy: 0.9782 - val_loss: 0.0606 - val_accuracy: 0.9855\n",
            "Epoch 5/32\n",
            "31/31 [==============================] - 209s 7s/step - loss: 0.0532 - accuracy: 0.9865 - val_loss: 0.0588 - val_accuracy: 0.9879\n",
            "Epoch 6/32\n",
            "31/31 [==============================] - 210s 7s/step - loss: 0.0498 - accuracy: 0.9834 - val_loss: 0.0667 - val_accuracy: 0.9782\n",
            "Epoch 7/32\n",
            "31/31 [==============================] - 209s 7s/step - loss: 0.0335 - accuracy: 0.9855 - val_loss: 0.1799 - val_accuracy: 0.9540\n",
            "Epoch 8/32\n",
            "31/31 [==============================] - 209s 7s/step - loss: 0.0578 - accuracy: 0.9803 - val_loss: 0.3873 - val_accuracy: 0.9104\n",
            "Epoch 9/32\n",
            "31/31 [==============================] - 209s 7s/step - loss: 0.1021 - accuracy: 0.9792 - val_loss: 0.1197 - val_accuracy: 0.9709\n",
            "Epoch 10/32\n",
            "31/31 [==============================] - 208s 7s/step - loss: 0.0424 - accuracy: 0.9875 - val_loss: 0.1044 - val_accuracy: 0.9831\n",
            "Epoch 11/32\n",
            "31/31 [==============================] - 208s 7s/step - loss: 0.0701 - accuracy: 0.9803 - val_loss: 0.6672 - val_accuracy: 0.8717\n",
            "Epoch 12/32\n",
            "31/31 [==============================] - 208s 7s/step - loss: 0.1923 - accuracy: 0.9626 - val_loss: 0.1543 - val_accuracy: 0.9492\n",
            "Epoch 13/32\n",
            "31/31 [==============================] - 207s 7s/step - loss: 0.0991 - accuracy: 0.9709 - val_loss: 0.0849 - val_accuracy: 0.9782\n",
            "Epoch 14/32\n",
            "31/31 [==============================] - 207s 7s/step - loss: 0.0831 - accuracy: 0.9740 - val_loss: 0.1292 - val_accuracy: 0.9734\n",
            "Epoch 15/32\n",
            "31/31 [==============================] - 208s 7s/step - loss: 0.0698 - accuracy: 0.9823 - val_loss: 0.0773 - val_accuracy: 0.9782\n",
            "Epoch 16/32\n",
            "31/31 [==============================] - 211s 7s/step - loss: 0.0216 - accuracy: 0.9938 - val_loss: 0.0575 - val_accuracy: 0.9879\n",
            "Epoch 17/32\n",
            "31/31 [==============================] - 209s 7s/step - loss: 0.1198 - accuracy: 0.9782 - val_loss: 0.0625 - val_accuracy: 0.9831\n",
            "Epoch 18/32\n",
            "31/31 [==============================] - 209s 7s/step - loss: 0.0299 - accuracy: 0.9917 - val_loss: 0.0947 - val_accuracy: 0.9855\n",
            "Epoch 19/32\n",
            "31/31 [==============================] - 212s 7s/step - loss: 0.0177 - accuracy: 0.9917 - val_loss: 0.0544 - val_accuracy: 0.9903\n",
            "Epoch 20/32\n",
            "31/31 [==============================] - 209s 7s/step - loss: 0.0063 - accuracy: 0.9990 - val_loss: 0.0768 - val_accuracy: 0.9855\n",
            "Epoch 21/32\n",
            "31/31 [==============================] - 209s 7s/step - loss: 0.0067 - accuracy: 0.9969 - val_loss: 0.0966 - val_accuracy: 0.9782\n",
            "Epoch 22/32\n",
            "31/31 [==============================] - 208s 7s/step - loss: 0.0033 - accuracy: 1.0000 - val_loss: 0.1530 - val_accuracy: 0.9782\n",
            "Epoch 23/32\n",
            "31/31 [==============================] - 208s 7s/step - loss: 0.0031 - accuracy: 0.9990 - val_loss: 0.1038 - val_accuracy: 0.9855\n",
            "Epoch 24/32\n",
            "31/31 [==============================] - 208s 7s/step - loss: 0.0024 - accuracy: 1.0000 - val_loss: 0.1230 - val_accuracy: 0.9855\n",
            "Epoch 25/32\n",
            "31/31 [==============================] - 208s 7s/step - loss: 0.0012 - accuracy: 1.0000 - val_loss: 0.1241 - val_accuracy: 0.9855\n",
            "Epoch 26/32\n",
            "31/31 [==============================] - 208s 7s/step - loss: 7.7516e-04 - accuracy: 1.0000 - val_loss: 0.1691 - val_accuracy: 0.9806\n",
            "Epoch 27/32\n",
            "31/31 [==============================] - 209s 7s/step - loss: 5.1150e-04 - accuracy: 1.0000 - val_loss: 0.1327 - val_accuracy: 0.9855\n",
            "Epoch 28/32\n",
            "31/31 [==============================] - 209s 7s/step - loss: 2.1692e-04 - accuracy: 1.0000 - val_loss: 0.1353 - val_accuracy: 0.9831\n",
            "Epoch 29/32\n",
            "31/31 [==============================] - 209s 7s/step - loss: 1.0779e-04 - accuracy: 1.0000 - val_loss: 0.1234 - val_accuracy: 0.9855\n",
            "Epoch 30/32\n",
            "31/31 [==============================] - 209s 7s/step - loss: 2.3354e-04 - accuracy: 1.0000 - val_loss: 0.1340 - val_accuracy: 0.9855\n",
            "Epoch 31/32\n",
            "31/31 [==============================] - 209s 7s/step - loss: 1.0640e-05 - accuracy: 1.0000 - val_loss: 0.1370 - val_accuracy: 0.9831\n",
            "Epoch 32/32\n",
            "31/31 [==============================] - 208s 7s/step - loss: 1.1317e-04 - accuracy: 1.0000 - val_loss: 0.1376 - val_accuracy: 0.9855\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "We could see that our model has performed with **100%** accuracy"
      ],
      "metadata": {
        "id": "enxfUDSj1uMK"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Save model**"
      ],
      "metadata": {
        "id": "3KLw-uy-15Nx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model.save('facedetection.h5')"
      ],
      "metadata": {
        "id": "HiZZrPWl0Cc-"
      },
      "execution_count": 45,
      "outputs": []
    }
  ]
}